{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd3bcd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files will be saved to: d:\\prompteng\\recordings\n",
      "Recording for 10 seconds\n",
      "Speak now!\n",
      "Recording saved: recordings\\recording_20250714_213636.wav\n",
      "Transcribing recordings\\recording_20250714_213636.wav\n",
      "Uploaded file\n",
      "What is capital of India\n",
      "The capital of India is New Delhi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "import pyttsx3\n",
    "import google.generativeai as genai  # Assuming this is the correct module\n",
    "\n",
    "# Load API key from environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set GEMINI_API_KEY in the .env file.\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "class Speechtotext:\n",
    "    def __init__(self, audio_dir=\"recordings\"):\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "        self.channels = 1\n",
    "        self.sample_rate = 44100\n",
    "        self.dtype = np.int16\n",
    "        self.transcript_dir=Path(\"transcripts\")\n",
    "        self.transcript_dir.mkdir(exist_ok=True)\n",
    "        self.audio_dir = Path(audio_dir)  # Corrected: was `os.audio_dir =`\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "        print(f\"Audio files will be saved to: {self.audio_dir.absolute()}\")\n",
    "\n",
    "    def record(self, duration=10):\n",
    "        filepath = self.audio_dir / f\"recording_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav\"\n",
    "        print(\"Recording for 10 seconds\")\n",
    "        print(\"Speak now!\")\n",
    "        audio_data = sd.rec(\n",
    "            int(duration * self.sample_rate),\n",
    "            samplerate=self.sample_rate,\n",
    "            channels=self.channels,\n",
    "            dtype=self.dtype\n",
    "        )\n",
    "        sd.wait()\n",
    "        wavfile.write(filepath, self.sample_rate, audio_data)\n",
    "        print(f\"Recording saved: {filepath}\")\n",
    "        return str(filepath)\n",
    "\n",
    "    def transcribe(self, filepath):\n",
    "        try:\n",
    "            print(f\"Transcribing {filepath}\")\n",
    "            audio_file_obj = genai.upload_file(\n",
    "                path=filepath,\n",
    "                mime_type=\"audio/wav\"\n",
    "            )\n",
    "            print(\"Uploaded file\")\n",
    "\n",
    "            max_wait_time = 60\n",
    "            wait_time = 0\n",
    "\n",
    "            while audio_file_obj.state.name == \"PROCESSING\":\n",
    "                print(\"Processing audio file...\")\n",
    "                time.sleep(2)\n",
    "                wait_time += 2\n",
    "\n",
    "                if wait_time > max_wait_time:\n",
    "                    print(\"Processing timeout exceeded\")\n",
    "                    genai.delete_file(audio_file_obj.name)\n",
    "                    return None\n",
    "                audio_file_obj = genai.get_file(audio_file_obj.name)\n",
    "\n",
    "            if audio_file_obj.state.name == \"FAILED\":\n",
    "                print(\"Audio processing failed\")\n",
    "                genai.delete_file(audio_file_obj.name)\n",
    "                return None\n",
    "\n",
    "            response = self.model.generate_content([\n",
    "                \"Transcript the audio file and give response to this audio file in form transcript: line break response dont include any special symbol and answer in natural language\",\n",
    "                audio_file_obj\n",
    "            ])\n",
    "            print(response.text)\n",
    "            filepath1 = self.transcript_dir / f\"transcript_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "            with open(filepath1, \"w\") as f:\n",
    "                f.write(response.text)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def record_and_transcribe(self):\n",
    "        filepath = self.record()\n",
    "        return self.transcribe(filepath)\n",
    "\n",
    "    def speak(self, text):\n",
    "        tts = self.TextToSpeech()\n",
    "        tts.speak(text)\n",
    "\n",
    "    class TextToSpeech:\n",
    "        def __init__(self):\n",
    "            self.engine = pyttsx3.init()\n",
    "            self.engine.setProperty('rate', 170)\n",
    "            self.engine.setProperty('volume', 1.0)\n",
    "\n",
    "        def speak(self, text):\n",
    "            self.engine.say(text)\n",
    "            self.engine.runAndWait()\n",
    "\n",
    "def main():\n",
    "    bot = Speechtotext()\n",
    "    response = bot.record_and_transcribe()\n",
    "    if response:\n",
    "        bot.speak(response)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
