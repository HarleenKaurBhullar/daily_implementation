{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59af234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: fitz 0.0.1.dev2\n",
      "Uninstalling fitz-0.0.1.dev2:\n",
      "  Would remove:\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/bin/fitz\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/bin/log2design.py\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/.DS_Store\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/fitz-0.0.1.dev2.dist-info/*\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/fitz/*\n",
      "    /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/scripts/*\n",
      "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fitz  # remove wrong one if present\n",
    "!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f80054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "doc=fitz.open(\"../Downloads/mlppt.pdf\")\n",
    "text1=\"\"\n",
    "for i in doc:\n",
    "    text1+=i.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c013233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloREGRESSION ANALYSIS : LINEAR \n",
      "BY – MAUAJAMA FIRDAUS & TULIKA SAHA\n",
      "MACHINE LEARNING\n",
      "• It is the science of getting computer to learn without being \n",
      "explicitly programmed.\n",
      "• Machine learning is an area of artificial intelligence concerned \n",
      "with the development of techniques which allow computers \n",
      "to \"learn\".\n",
      "•  More specifically, machine learning is a method for creating \n",
      "computer programs by the analysis of data sets.\n",
      "APPLICATIONS\n",
      "• Search Engines like Google, Bing etc.\n",
      "• Facebook photo tagging application.\n",
      "• Self Customizing Programs and many more.\n",
      "           \n",
      "SUPERVISED LEARNING\n",
      "• Given the “right answer” for each of our \n",
      "examples in the training set.\n",
      "• The task of the algorithm is to find many more \n",
      "such right answers for new examples.\n",
      "• Consists of two problems-\n",
      "• Regression Problem\n",
      "• Classification Problem\n",
      "REGRESSION PROBLEM\n",
      "• The term “regression” refers to the fact that we are \n",
      "trying to predict a continuous-valued output.\n",
      "CLASSIFICATION PROBLEM\n",
      "• It refers to the fact that we are trying to \n",
      "predict discrete valued outputs.\n",
      "UNSUPERVISED LEARENING\n",
      "• Given a set of data or examples in the training \n",
      "set without prior information of what the data \n",
      "is all about.\n",
      "• The task of the algorithm is to find the \n",
      "structure among the data.\n",
      "• Clustering Problem is an example of \n",
      "Unsupervised Learning.\n",
      "LINEAR REGRESSION\n",
      "Why are we looking at this algorithm ?\n",
      "• Machine Learning – a field of predictive modelling\n",
      "• Linear Regression\n",
      "– Developed in the field of statistic\n",
      "– A model that attempts to show the relationship \n",
      "between two variables with a linear equation\n",
      "– Borrowed by Machine Learning\n",
      "• Finds it’s application in\n",
      "– Evaluating  Trends and Sales Estimates\n",
      "– Analyzing the Impact of Price Change and many more\n",
      "LINEAR REGRESSION\n",
      "• Basic Framework \n",
      "– Dependent variable y , also called the \n",
      "output/explained variable which is to be predicted\n",
      "– Independent variables       , also called the \n",
      "input/explanatory variables that is to be used for \n",
      "making predictions.\n",
      "• Regression is the general task of attempting to \n",
      "predict the value of output variable y from the \n",
      "input variables      .\n",
      "MODEL REPRESENTATION\n",
      "MODEL REPRESENTATION\n",
      "MODEL REPRESENTATION\n",
      "How do we represent h ?\n",
      "MODEL REPRESENTATION\n",
      " Given a training set ,\n",
      "Hypothesis :                                           \n",
      "  where \n",
      "  How to choose \n",
      "MODEL REPRESENTATION\n",
      "COST FUNCTION\n",
      "Idea : Choose     ,      so that             is as close to y       \n",
      "for our training examples (x , y) .\n",
      "COST FUNCTION\n",
      "So going with the idea ,\n",
      "If hypothesis :\n",
      "We want to minimise the squared error function\n",
      "i.e.                                     i.e the difference \n",
      "between the predicted value (            ) and the \n",
      "actual label (y) should be as minimum as \n",
      "possible.\n",
      "COST FUNCTION\n",
      "Therefore, the cost function becomes\n",
      " where summation(      ) represents sum over my \n",
      "training set from i to m .\n",
      " and where (        ) represents that minimising one\n",
      "half of something shall give us same values of \n",
      " and       as minimising the entire thing.\n",
      " \n",
      "COST FUNCTION\n",
      "So, overall we want to find the value of       &      \n",
      "   that minimises the entire expression.\n",
      "GRADIENT DESCENT ALGORITHM\n",
      "• Gradient Descent algorithm is basically used to \n",
      "minimise some function J(say a cost function).\n",
      "• Problem Setup\n",
      "–  Have some function J(      ,      )\n",
      "– Want to \n",
      "• Outline\n",
      "– Start with some        &       (say      = 0 ,      = 0)\n",
      "– Keep changing       ,      to reduce J(      ,      ) until \n",
      "we hopefully end up at a minimum.\n",
      "GRADIENT DESCENT ALGORITHM\n",
      "where := is the assignment operator\n",
      "  α is the learning rate that controls how big a step we \n",
      "can take downhill while creating descent\n",
      "• Simultaneous update\n",
      "GRADIENT DESCENT INTUITION\n",
      "For eg :) say we have only one parameter, so,\n",
      "                       &               , hence the GD equation becomes  \n",
      "                  \n",
      "                   \n",
      "                       is the derivative term which basically \n",
      "                   denotes the slope of the line that is just   \n",
      "    tangent  to the function              at the point \n",
      " \n",
      "GRADIENT DESCENT INTUITION\n",
      "                           \n",
      "                           \n",
      "                             \n",
      "      \n",
      "GRADIENT DESCENT INTUITION\n",
      "                               \n",
      "GRADIENT DESCENT INTUITION\n",
      "If       is too small , then \n",
      "gradient  descent will \n",
      "converge slowly \n",
      "because very small and \n",
      "hence lot of steps are \n",
      "being taken before it \n",
      "gets anywhere close to \n",
      "the global minimum.\n",
      "GRADIENT DESCENT INTUITION\n",
      "If       is too large, then \n",
      "gradient descent will \n",
      "overshoot the minimum \n",
      "because the steps taken \n",
      "are huge . It may fail to \n",
      "converge .\n",
      "GRADIENT DESCENT FOR LINEAR \n",
      "REGRESSION\n",
      "So, applying GD algorithm to minimise the \n",
      "squared error cost function i.e.                     \n",
      " where , \n",
      "                                                                          &\n",
      "Calculating the derivative part,\n",
      "                      \n",
      "GRADIENT DESCENT FOR LINEAR \n",
      "REGRESSION\n",
      "So for      , or j = 0 :\n",
      " for      , or j = 1 :\n",
      "GRADIENT DESCENT FOR LINEAR \n",
      "REGRESSION\n",
      "Now , by applying GD algorithm to the previous \n",
      "equation(derivative part) ,\n",
      "FEATURE SCALING\n",
      "• If one feature has a range say 0-2000 & another \n",
      "say 0-5 i.e. a 2000 to 5 ratio, then the contours of \n",
      "the cost funtion takes up a very skewed elliptical \n",
      "shape & the GD may end up taking a long time & \n",
      "can oscillate back & forth before it can finally find \n",
      "its way to the global minimum.\n",
      "• A useful thing to do is scale the features i.e. the \n",
      "different features take on similar range of values.\n",
      "• So, by feature scaling we get the features in a \n",
      "range of -1 to +1 .\n",
      "LINEAR REGRESSION WITH MULTIPLE \n",
      "VARIABLES\n",
      "for multiple features ,\n",
      "For convenience of notation , define       = 1\n",
      " \n",
      "                            , \n",
      "So, \n",
      "      \n",
      "POLYNOMIAL REGRESSION\n",
      "• It allows to use the machinery of linear regression to fit very \n",
      "complicated even non-linear function to the data.\n",
      "Quadratic model : \n",
      "Cubic model : \n",
      "POLYNOMIAL REGRESSION\n",
      "The form of hypothesis is :\n",
      " where                  ,                    ,  \n",
      "• Feature Scaling is required here\n",
      "NORMAL EQUATION\n",
      "• GD is basically an algorithm for linear regression \n",
      "that takes multiple iterations to reach the global \n",
      "minimum or to minimise a cost function         .\n",
      "• Normal Equation is a method to solve for     \n",
      "analytically i.e. in one step we get the optimum \n",
      "value .\n",
      "• Intuition : If 1D ,         \n",
      "  \n",
      "  To minimise the above quadratic function, we \n",
      "calculate the derivative of the function and set it \n",
      "to 0 i.e.                        & solve for      .\n",
      "NORMAL EQUATION\n",
      "GRADIENT DESCENT Vs NORMAL \n",
      "EQUATION\n",
      "GRADIENT DESCENT\n",
      "• Need to choose        .\n",
      "• Needs many iterations\n",
      "• Works well even if n is large \n",
      "where n is the no. of \n",
      "features.\n",
      "NORMAL EQUATION\n",
      "• No need to choose       .\n",
      "• Needs no iteration\n",
      "• Slow if n is large because it \n",
      "needs to compute                 \n",
      "      which is n*n matrix .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = splitter.split_text(text1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c559769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HelloREGRESSION ANALYSIS : LINEAR \\nBY – MAUAJAMA FIRDAUS & TULIKA SAHA\\nMACHINE LEARNING\\n• It is the science of getting computer to learn without being \\nexplicitly programmed.\\n• Machine learning is an area of artificial intelligence concerned \\nwith the development of techniques which allow computers \\nto \"learn\".\\n•  More specifically, machine learning is a method for creating \\ncomputer programs by the analysis of data sets.\\nAPPLICATIONS\\n• Search Engines like Google, Bing etc.', 'APPLICATIONS\\n• Search Engines like Google, Bing etc.\\n• Facebook photo tagging application.\\n• Self Customizing Programs and many more.\\n           \\nSUPERVISED LEARNING\\n• Given the “right answer” for each of our \\nexamples in the training set.\\n• The task of the algorithm is to find many more \\nsuch right answers for new examples.\\n• Consists of two problems-\\n• Regression Problem\\n• Classification Problem\\nREGRESSION PROBLEM\\n• The term “regression” refers to the fact that we are', '• Classification Problem\\nREGRESSION PROBLEM\\n• The term “regression” refers to the fact that we are \\ntrying to predict a continuous-valued output.\\nCLASSIFICATION PROBLEM\\n• It refers to the fact that we are trying to \\npredict discrete valued outputs.\\nUNSUPERVISED LEARENING\\n• Given a set of data or examples in the training \\nset without prior information of what the data \\nis all about.\\n• The task of the algorithm is to find the \\nstructure among the data.\\n• Clustering Problem is an example of', 'structure among the data.\\n• Clustering Problem is an example of \\nUnsupervised Learning.\\nLINEAR REGRESSION\\nWhy are we looking at this algorithm ?\\n• Machine Learning – a field of predictive modelling\\n• Linear Regression\\n– Developed in the field of statistic\\n– A model that attempts to show the relationship \\nbetween two variables with a linear equation\\n– Borrowed by Machine Learning\\n• Finds it’s application in\\n– Evaluating  Trends and Sales Estimates', '– Borrowed by Machine Learning\\n• Finds it’s application in\\n– Evaluating  Trends and Sales Estimates\\n– Analyzing the Impact of Price Change and many more\\nLINEAR REGRESSION\\n• Basic Framework \\n– Dependent variable y , also called the \\noutput/explained variable which is to be predicted\\n– Independent variables       , also called the \\ninput/explanatory variables that is to be used for \\nmaking predictions.\\n• Regression is the general task of attempting to', 'making predictions.\\n• Regression is the general task of attempting to \\npredict the value of output variable y from the \\ninput variables      .\\nMODEL REPRESENTATION\\nMODEL REPRESENTATION\\nMODEL REPRESENTATION\\nHow do we represent h ?\\nMODEL REPRESENTATION\\n Given a training set ,\\nHypothesis :                                           \\n  where \\n  How to choose \\nMODEL REPRESENTATION\\nCOST FUNCTION\\nIdea : Choose     ,      so that             is as close to y       \\nfor our training examples (x , y) .', 'for our training examples (x , y) .\\nCOST FUNCTION\\nSo going with the idea ,\\nIf hypothesis :\\nWe want to minimise the squared error function\\ni.e.                                     i.e the difference \\nbetween the predicted value (            ) and the \\nactual label (y) should be as minimum as \\npossible.\\nCOST FUNCTION\\nTherefore, the cost function becomes\\n where summation(      ) represents sum over my \\ntraining set from i to m .\\n and where (        ) represents that minimising one', 'training set from i to m .\\n and where (        ) represents that minimising one\\nhalf of something shall give us same values of \\n and       as minimising the entire thing.\\n \\nCOST FUNCTION\\nSo, overall we want to find the value of       &      \\n   that minimises the entire expression.\\nGRADIENT DESCENT ALGORITHM\\n• Gradient Descent algorithm is basically used to \\nminimise some function J(say a cost function).\\n• Problem Setup\\n–  Have some function J(      ,      )\\n– Want to \\n• Outline', '• Problem Setup\\n–  Have some function J(      ,      )\\n– Want to \\n• Outline\\n– Start with some        &       (say      = 0 ,      = 0)\\n– Keep changing       ,      to reduce J(      ,      ) until \\nwe hopefully end up at a minimum.\\nGRADIENT DESCENT ALGORITHM\\nwhere := is the assignment operator\\n  α is the learning rate that controls how big a step we \\ncan take downhill while creating descent\\n• Simultaneous update\\nGRADIENT DESCENT INTUITION\\nFor eg :) say we have only one parameter, so,', '• Simultaneous update\\nGRADIENT DESCENT INTUITION\\nFor eg :) say we have only one parameter, so,\\n                       &               , hence the GD equation becomes  \\n                  \\n                   \\n                       is the derivative term which basically \\n                   denotes the slope of the line that is just   \\n    tangent  to the function              at the point \\n \\nGRADIENT DESCENT INTUITION', 'GRADIENT DESCENT INTUITION\\n                           \\n                           \\n                             \\n      \\nGRADIENT DESCENT INTUITION\\n                               \\nGRADIENT DESCENT INTUITION\\nIf       is too small , then \\ngradient  descent will \\nconverge slowly \\nbecause very small and \\nhence lot of steps are \\nbeing taken before it \\ngets anywhere close to \\nthe global minimum.\\nGRADIENT DESCENT INTUITION\\nIf       is too large, then \\ngradient descent will \\novershoot the minimum', 'If       is too large, then \\ngradient descent will \\novershoot the minimum \\nbecause the steps taken \\nare huge . It may fail to \\nconverge .\\nGRADIENT DESCENT FOR LINEAR \\nREGRESSION\\nSo, applying GD algorithm to minimise the \\nsquared error cost function i.e.                     \\n where , \\n                                                                          &\\nCalculating the derivative part,\\n                      \\nGRADIENT DESCENT FOR LINEAR \\nREGRESSION\\nSo for      , or j = 0 :', 'GRADIENT DESCENT FOR LINEAR \\nREGRESSION\\nSo for      , or j = 0 :\\n for      , or j = 1 :\\nGRADIENT DESCENT FOR LINEAR \\nREGRESSION\\nNow , by applying GD algorithm to the previous \\nequation(derivative part) ,\\nFEATURE SCALING\\n• If one feature has a range say 0-2000 & another \\nsay 0-5 i.e. a 2000 to 5 ratio, then the contours of \\nthe cost funtion takes up a very skewed elliptical \\nshape & the GD may end up taking a long time &', 'the cost funtion takes up a very skewed elliptical \\nshape & the GD may end up taking a long time & \\ncan oscillate back & forth before it can finally find \\nits way to the global minimum.\\n• A useful thing to do is scale the features i.e. the \\ndifferent features take on similar range of values.\\n• So, by feature scaling we get the features in a \\nrange of -1 to +1 .\\nLINEAR REGRESSION WITH MULTIPLE \\nVARIABLES\\nfor multiple features ,\\nFor convenience of notation , define       = 1', 'VARIABLES\\nfor multiple features ,\\nFor convenience of notation , define       = 1\\n \\n                            , \\nSo, \\n      \\nPOLYNOMIAL REGRESSION\\n• It allows to use the machinery of linear regression to fit very \\ncomplicated even non-linear function to the data.\\nQuadratic model : \\nCubic model : \\nPOLYNOMIAL REGRESSION\\nThe form of hypothesis is :\\n where                  ,                    ,  \\n• Feature Scaling is required here\\nNORMAL EQUATION', 'where                  ,                    ,  \\n• Feature Scaling is required here\\nNORMAL EQUATION\\n• GD is basically an algorithm for linear regression \\nthat takes multiple iterations to reach the global \\nminimum or to minimise a cost function         .\\n• Normal Equation is a method to solve for     \\nanalytically i.e. in one step we get the optimum \\nvalue .\\n• Intuition : If 1D ,         \\n  \\n  To minimise the above quadratic function, we \\ncalculate the derivative of the function and set it', 'calculate the derivative of the function and set it \\nto 0 i.e.                        & solve for      .\\nNORMAL EQUATION\\nGRADIENT DESCENT Vs NORMAL \\nEQUATION\\nGRADIENT DESCENT\\n• Need to choose        .\\n• Needs many iterations\\n• Works well even if n is large \\nwhere n is the no. of \\nfeatures.\\nNORMAL EQUATION\\n• No need to choose       .\\n• Needs no iteration\\n• Slow if n is large because it \\nneeds to compute                 \\n      which is n*n matrix .']\n"
     ]
    }
   ],
   "source": [
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f168f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: tqdm in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (2.7.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: scipy in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached scikit_learn-1.7.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sentence-transformers\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [sentence-transformers]/4\u001b[0m [sentence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 scikit-learn-1.7.0 sentence-transformers-5.0.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653a246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model1 = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b08a959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model1.encode(chunks, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "684a02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0230263   0.02633102 -0.02139618 ...  0.0645209   0.03129127\n",
      "  -0.01591179]\n",
      " [-0.05722002  0.00974867 -0.02937329 ...  0.07207264  0.02376742\n",
      "   0.05307517]\n",
      " [-0.0881372  -0.00038858 -0.05518571 ...  0.09440378  0.02548493\n",
      "  -0.00013326]\n",
      " ...\n",
      " [ 0.06068417 -0.05367035 -0.02901027 ...  0.01948629  0.09434402\n",
      "  -0.04756236]\n",
      " [-0.04206353 -0.03201394  0.05732423 ...  0.07373676  0.05356347\n",
      "   0.01690619]\n",
      " [ 0.06014205  0.0471612  -0.06064006 ...  0.0247572   0.0403459\n",
      "  -0.02249638]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20e4b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (1.0.15)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (2.2.6)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.6.15)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.56b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.33.2)\n",
      "Requirement already satisfied: filelock in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/harleen/anaconda3/envs/dscodecamp/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90fca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [chunks] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      4\u001b[39m client = chromadb.Client(Settings())\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m collection = client.create_collection(\u001b[33m\"\u001b[39m\u001b[33mchunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[32m      8\u001b[39m     collection.add(documents=[chunk], ids=[\u001b[38;5;28mstr\u001b[39m(i)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/chromadb/api/client.py:168\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m model = \u001b[38;5;28mself\u001b[39m._server.create_collection(\n\u001b[32m    169\u001b[39m     name=name,\n\u001b[32m    170\u001b[39m     metadata=metadata,\n\u001b[32m    171\u001b[39m     tenant=\u001b[38;5;28mself\u001b[39m.tenant,\n\u001b[32m    172\u001b[39m     database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    173\u001b[39m     get_or_create=get_or_create,\n\u001b[32m    174\u001b[39m     configuration=configuration,\n\u001b[32m    175\u001b[39m )\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    177\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    178\u001b[39m     model=model,\n\u001b[32m    179\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    180\u001b[39m     data_loader=data_loader,\n\u001b[32m    181\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dscodecamp/lib/python3.13/site-packages/chromadb/api/rust.py:227\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m collection = \u001b[38;5;28mself\u001b[39m.bindings.create_collection(\n\u001b[32m    228\u001b[39m     name, configuration_json_str, metadata, get_or_create, tenant, database\n\u001b[32m    229\u001b[39m )\n\u001b[32m    230\u001b[39m collection_model = CollectionModel(\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    232\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     database=collection.database,\n\u001b[32m    238\u001b[39m )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [chunks] already exists"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings())\n",
    "collection = client.create_collection(\"chunks\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    collection.add(documents=[chunk], ids=[str(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f157fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is feature scaling?\"\n",
    "\n",
    "# Use the same SentenceTransformer model\n",
    "query_embedding = model1.encode([query], convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "804b5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "relevant_chunks = results['documents'][0]  # Top 3 retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cac43169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded? True\n",
      "Based on the document, feature scaling involves scaling the different features so that they take on a similar range of values. By doing this, the features are brought into a range of -1 to +1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()  # This loads the .env file\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(\"API Key loaded?\", api_key is not None)\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "model2= genai.GenerativeModel(\"gemini-2.0-flash\")  \n",
    "\n",
    "context = \"\\n\\n\".join(relevant_chunks)\n",
    "final_prompt = f\"\"\"\n",
    "You are a helpful assistant. Based on the following document sections only, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "response = model2.generate_content(final_prompt)\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dscodecamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
